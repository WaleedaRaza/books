<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session 2a41b668-3c08-464e-92d2-ee5a21e21f19 (2025-12-23 18:34Z) -->

# Waleed's picks platform roadmap (2025-12-23 18:34Z)

_**User (2025-12-23 18:34Z)**_

Today we will convert library of alexandrai from a finnicky sandbox., to a production grade platform. Here are what we will have:

my complete library, referred to as waleeds picks. The library will be page one. on page 2 we have pipeline. i will emphasize right now, that the procedure vie been using to get books for my kindle, will serve as the foundation for this prod grade tool. ive been using and iteratively improving the programs in this dir for about a year now. Here is the process i follow, and how that pipeline will be used by users. I paste a list of books  wa atuhors in scirpt 1. script 2 takes that list, normalizes if needed, adds free pdf online, and uses ddg api to open not just the serarch query, but it then ulls from script 33, which evaluates links, and selects the .pdf's to open. I then go thrpough the tabs, delete any broken or non fair use links, and then script 4, uses a macro to fgo to that window, ctrl S, enter, ctrl w, and saves all the books into a dir i specified. script 5 renames, them. no w users. I will be extremly hard pressed, if we cannot translate these scripts into being user facing. all it will take is 1. the books list, 2. opnening the windows and refining link selection,. 3. having them be able to choose links from our site on a dashboard in the pipeiline, or mamnually go choose waht they want, when they have it set, they select the crome window and on our platform they hit downlaod. rather than tell them navigate to it as it does the macros to download, we need a nelegant way for us to download them, and then show the useres all the files, we will ilkely have some blanck webpages, or fake sites we doewnloadk, but we can use an llm or logic to filter, giving the user less palces to fuck up the tool. my fear is at the stage where links are being opened, and then downlaofed, users may ghet lost and get their other chrom windows screwed, or click off mid macro run and aaccidentally save and delete other things, so we need elegance, but we have to show ppl tghe technical depth and use the simplified procvess at aclae to make it sophisticated. the final stage would be seleciton and approval, to ensure things are fair use, they slect books they want and then they sbumit for approval, whgich is usually <1 hour. at which point like the lib of alexandria in egypt, we ekep a copy, and give them a fair use copy. this gorws our platform. After this we have basic wishlist creation features, but utlimately its app, that we will also have an api for in case it gets taken down. its service based and data app, I need use to brainstorm the most elegant way to do this. ideaslly coding shoukld only be the final 10% of our work, bc we have a great foundation, alr almost every script, working ui, a foundation of books and more to use to experiment on importation as we enhance the platform. you cannot and will not fuck up planning. i want youre interpretation, and planning, and then i will give it to my consultant, if he approves we begin, you should root your reaosining in current state vs learning what the true desried state is, its the 2025 lightweight wikip[edia1) Product surfaces
Page 1 â€” Waleedâ€™s Picks

Browse/search catalog

Each book shows: metadata, pipeline status, approved asset(s), provenance/audit log

Goal: credibility + a living demo dataset

Page 2 â€” Pipeline

A guided flow that maps 1:1 to your current process, but without user-chaos:

Paste list â†’ normalize â†’ discover candidates â†’ evaluate/score â†’ user selects â†’ submit for approval â†’ ingest/download â†’ rename/commit

2) Pipeline state machine
Core entities

BookRequest: one title/author line from user input

CandidateLink: a discovered URL + extracted signals + score

Asset: an ingested file record (hash, size, storage path)

ApprovalDecision: approved/rejected + reviewer notes + timestamp

JobRun: execution record per stage (stdout, errors, metrics)

States (minimal but complete)
LIST_DRAFT
â†’ NORMALIZED
â†’ CANDIDATES_FOUND
â†’ CANDIDATES_SCORED
â†’ USER_REVIEWED
â†’ SUBMITTED_FOR_APPROVAL
â†’ APPROVED | REJECTED
â†’ INGESTING
â†’ INGESTED
â†’ RENAMED
â†’ COMMITTED

Transitions (what triggers what)

User action triggers: submit list, confirm selections, submit for approval

System triggers: run normalization, discovery, scoring, ingestion, renaming

Admin action triggers: approve/reject

This state machine is your â€œproduction skeleton.â€ Everything else is implementation details.

3) â€œScripts â†’ Productionâ€ mapping

You do not rewrite scripts. You wrap them.

Script 1 (paste list)
â†’ UI + parser â†’ creates BookRequests

Script 2 (normalize + query expansion + DDG search/open)
â†’ split into two safe functions:

Normalize (pure): input â†’ normalized book objects

Discover (side-effect): takes normalized books â†’ returns CandidateLinks (no user browser)

Script 3 (evaluate links, select PDFs)
â†’ â€œScoring Workerâ€: candidate URL â†’ extracted signals â†’ score + flags

Script 4 (macro Ctrl+S)
â†’ replace with server-side fetch/ingest (controlled environment).
UX shows previews + progress. No macros. No tab chaos.

Script 5 (rename)
â†’ â€œRename Workerâ€: Asset + rules â†’ final filename + metadata embed (optional)

4) Architecture (Vercel-first, production-grade)
Frontend / App

Next.js (App Router) on Vercel

Routes:

/ Waleedâ€™s Picks

/pipeline pipeline wizard + dashboard

/admin/approvals review queue

/api/* thin API endpoints (auth + job control)

Data layer

Postgres (Supabase or Neon)

tables: users, book_requests, candidate_links, assets, approvals, job_runs, audit_events

Object storage (S3/R2/Supabase Storage)

staging bucket + committed bucket

Compute (the key decision)

Vercel is great for web + short functions, but your pipeline needs durable background jobs.

Use a dedicated worker layer:

Option A: Cloudflare Workers + Queues (fast, cheap, great for URL fetch + scoring)

Option B: Render/Fly.io worker service running Node/Python jobs

Option C: Supabase Edge Functions + background (works, but queues are the main limiter)

My recommendation for your case:

Vercel for UI/API

Worker service for long-running stages (discover/score/ingest/rename)

Queue for orchestration (Upstash Redis / BullMQ, or Cloudflare Queues)

Orchestration

A simple job runner pattern:

Vercel API creates jobs, pushes to queue

Worker consumes jobs, updates DB state + job_runs

UI subscribes to status (polling or websockets/SSE)

Real-time updates (optional but great)

Start with polling (every 2â€“5s) for job status.

Upgrade to SSE via Vercel routes or a small realtime service later.

5) The pipeline UX that prevents user screw-ups
The golden rule

Users never leave your platform to â€œmanage tabs.â€

Instead, they review candidates inside a dashboard.

For each BookRequest:

show ranked candidates

show quick â€œpreviewâ€ signals:

filetype guess, size, domain, title snippet, â€œblank pageâ€ detector

user chooses:

âœ… accept

âŒ reject

ðŸ”— add link manually (power users)

Then:

Submit selected set â†’ goes into approval queue

This keeps the â€œtechnical depthâ€ but eliminates the macro chaos.

6) Database tables (minimum viable schema)

You can hand this to your consultant as your â€œsource of truthâ€:

users

libraries (waleeds_picks, user_library)

book_requests

id, user_id, raw_title, raw_author, normalized_title, normalized_author, status, created_at

candidate_links

id, book_request_id, url, domain, score, flags(json), extracted(json), status

approvals

id, book_request_id, reviewer_id, decision, notes, decided_at

assets

id, book_request_id, source_url, storage_key, sha256, size, mime, stage(staging|committed), created_at

job_runs

id, job_type, payload(json), status, started_at, finished_at, logs(text), error(text)

audit_events

who, what, entity_type, entity_id, metadata(json), timestamp

7) Roadmap to deployment on Vercel
Phase 0 â€” Lock desired state (1â€“2 days)

Deliverables (no code):

State machine finalized

Schema finalized

Worker/queue choice finalized

UI screens list finalized

Acceptance criteria per stage

Phase 1 â€” Vercel MVP shell (2â€“4 days)

Deploy Next.js skeleton to Vercel

Auth (Clerk / Supabase Auth)

Postgres connected

Page 1 (Waleedâ€™s Picks) reads from DB

Pipeline page renders BookRequests and statuses (even if mocked)

Phase 2 â€” Wrap scripts as workers (the real conversion) (4â€“10 days)

Create worker service (Node or Pythonâ€”whatever your scripts are)

Implement these job types:

normalize_list

discover_candidates

score_candidates

ingest_assets

rename_commit

Each job:

reads payload from DB/queue

writes outputs to tables

advances state

logs to job_runs

Phase 3 â€” Candidate review UI + approvals (3â€“7 days)

Candidate dashboard with:

ranking, preview signals, accept/reject

Admin approvals queue

Submission batching + SLA status

Audit log visible per book

Phase 4 â€” Ingestion/storage + delivery (3â€“7 days)

Staging bucket + committed bucket

Hashing + dedupe

Download bundles (zip) or per-file downloads

Rename rules applied automatically

Phase 5 â€” Hardening (ongoing, but quick wins first)

Rate limits

Observability (Sentry + structured logs)

Backoff/retry policies

â€œResume pipelineâ€ and â€œRe-run stageâ€ buttons

Safe-guard rails:

never delete user data automatically

idempotent jobs

immutable audit trail

8) Deployment checklist (Vercel)
Vercel

Next.js app

Environment vars:

DATABASE_URL

STORAGE credentials

QUEUE credentials

AUTH keys

Vercel cron (optional):

reconcile stuck jobs, refresh candidate scoring

Worker host

Dockerized worker (recommended)

Access to queue + DB + storage

Autoscaling (basic)

CI/CD

GitHub Actions:

typecheck/lint

unit tests for normalization + scoring

deploy to Vercel on main

deploy worker on main

9) The â€œcoding is last 10%â€ approach (how to actually do that)

Before any implementation, you and your consultant should produce three artifacts:

Pipeline Spec

states, transitions, error handling

idempotency rules

retry policies

Data Contract

exact JSON payloads for each job type

exact DB schema fields

UI Contract

screens + components + what data each consumes

user actions that trigger transitions

Once those are locked, coding becomes mostly:

wiring + wrappers + UI rendering

not rethinking fundamentals

10) Key design decisions you must choose once

To avoid future chaos, pick these now:

Worker runtime: Node vs Python (match your scripts)

Queue: Upstash Redis (simple) vs Cloudflare Queues (clean)

Storage: S3/R2 vs Supabase Storage

Auth: Clerk vs Supabase Auth

Preview strategy: HEAD requests + partial fetch vs full fetch

If you want the simplest path that matches your â€œlightweight Wikipediaâ€ vibe:

Vercel + Supabase (DB/Auth/Storage) + Upstash Redis queue + Worker on Render/Fly

Thatâ€™s a very common, fast-to-ship, scalable combo.

---

_**Agent (model composer-1, mode Agent)**_



---



---

