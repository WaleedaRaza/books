<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session 5c96af59-1e34-4463-abfb-fbd11f724cc5 (2025-12-23 18:41Z) -->

# Book processing pipeline architecture and roadmap (2025-12-23 18:41Z)

_**User (2025-12-23 18:43Z)**_

1) Product surfaces
Page 1 â€” Waleedâ€™s Picks

Browse/search catalog

Each book shows: metadata, pipeline status, approved asset(s), provenance/audit log

Goal: credibility + a living demo dataset

Page 2 â€” Pipeline

A guided flow that maps 1:1 to your current process, but without user-chaos:

Paste list â†’ normalize â†’ discover candidates â†’ evaluate/score â†’ user selects â†’ submit for approval â†’ ingest/download â†’ rename/commit

2) Pipeline state machine
Core entities

BookRequest: one title/author line from user input

CandidateLink: a discovered URL + extracted signals + score

Asset: an ingested file record (hash, size, storage path)

ApprovalDecision: approved/rejected + reviewer notes + timestamp

JobRun: execution record per stage (stdout, errors, metrics)

States (minimal but complete)
LIST_DRAFT
â†’ NORMALIZED
â†’ CANDIDATES_FOUND
â†’ CANDIDATES_SCORED
â†’ USER_REVIEWED
â†’ SUBMITTED_FOR_APPROVAL
â†’ APPROVED | REJECTED
â†’ INGESTING
â†’ INGESTED
â†’ RENAMED
â†’ COMMITTED

Transitions (what triggers what)

User action triggers: submit list, confirm selections, submit for approval

System triggers: run normalization, discovery, scoring, ingestion, renaming

Admin action triggers: approve/reject

This state machine is your â€œproduction skeleton.â€ Everything else is implementation details.

3) â€œScripts â†’ Productionâ€ mapping

You do not rewrite scripts. You wrap them.

Script 1 (paste list)
â†’ UI + parser â†’ creates BookRequests

Script 2 (normalize + query expansion + DDG search/open)
â†’ split into two safe functions:

Normalize (pure): input â†’ normalized book objects

Discover (side-effect): takes normalized books â†’ returns CandidateLinks (no user browser)

Script 3 (evaluate links, select PDFs)
â†’ â€œScoring Workerâ€: candidate URL â†’ extracted signals â†’ score + flags

Script 4 (macro Ctrl+S)
â†’ replace with server-side fetch/ingest (controlled environment).
UX shows previews + progress. No macros. No tab chaos.

Script 5 (rename)
â†’ â€œRename Workerâ€: Asset + rules â†’ final filename + metadata embed (optional)

4) Architecture (Vercel-first, production-grade)
Frontend / App

Next.js (App Router) on Vercel

Routes:

/ Waleedâ€™s Picks

/pipeline pipeline wizard + dashboard

/admin/approvals review queue

/api/* thin API endpoints (auth + job control)

Data layer

Postgres (Supabase or Neon)

tables: users, book_requests, candidate_links, assets, approvals, job_runs, audit_events

Object storage (S3/R2/Supabase Storage)

staging bucket + committed bucket

Compute (the key decision)

Vercel is great for web + short functions, but your pipeline needs durable background jobs.

Use a dedicated worker layer:

Option A: Cloudflare Workers + Queues (fast, cheap, great for URL fetch + scoring)

Option B: Render/Fly.io worker service running Node/Python jobs

Option C: Supabase Edge Functions + background (works, but queues are the main limiter)

My recommendation for your case:

Vercel for UI/API

Worker service for long-running stages (discover/score/ingest/rename)

Queue for orchestration (Upstash Redis / BullMQ, or Cloudflare Queues)

Orchestration

A simple job runner pattern:

Vercel API creates jobs, pushes to queue

Worker consumes jobs, updates DB state + job_runs

UI subscribes to status (polling or websockets/SSE)

Real-time updates (optional but great)

Start with polling (every 2â€“5s) for job status.

Upgrade to SSE via Vercel routes or a small realtime service later.

5) The pipeline UX that prevents user screw-ups
The golden rule

Users never leave your platform to â€œmanage tabs.â€

Instead, they review candidates inside a dashboard.

For each BookRequest:

show ranked candidates

show quick â€œpreviewâ€ signals:

filetype guess, size, domain, title snippet, â€œblank pageâ€ detector

user chooses:

âœ… accept

âŒ reject

ğŸ”— add link manually (power users)

Then:

Submit selected set â†’ goes into approval queue

This keeps the â€œtechnical depthâ€ but eliminates the macro chaos.

6) Database tables (minimum viable schema)

You can hand this to your consultant as your â€œsource of truthâ€:

users

libraries (waleeds_picks, user_library)

book_requests

id, user_id, raw_title, raw_author, normalized_title, normalized_author, status, created_at

candidate_links

id, book_request_id, url, domain, score, flags(json), extracted(json), status

approvals

id, book_request_id, reviewer_id, decision, notes, decided_at

assets

id, book_request_id, source_url, storage_key, sha256, size, mime, stage(staging|committed), created_at

job_runs

id, job_type, payload(json), status, started_at, finished_at, logs(text), error(text)

audit_events

who, what, entity_type, entity_id, metadata(json), timestamp

7) Roadmap to deployment on Vercel
Phase 0 â€” Lock desired state (1â€“2 days)

Deliverables (no code):

State machine finalized

Schema finalized

Worker/queue choice finalized

UI screens list finalized

Acceptance criteria per stage

Phase 1 â€” Vercel MVP shell (2â€“4 days)

Deploy Next.js skeleton to Vercel

Auth (Clerk / Supabase Auth)

Postgres connected

Page 1 (Waleedâ€™s Picks) reads from DB

Pipeline page renders BookRequests and statuses (even if mocked)

Phase 2 â€” Wrap scripts as workers (the real conversion) (4â€“10 days)

Create worker service (Node or Pythonâ€”whatever your scripts are)

Implement these job types:

normalize_list

discover_candidates

score_candidates

ingest_assets

rename_commit

Each job:

reads payload from DB/queue

writes outputs to tables

advances state

logs to job_runs

Phase 3 â€” Candidate review UI + approvals (3â€“7 days)

Candidate dashboard with:

ranking, preview signals, accept/reject

Admin approvals queue

Submission batching + SLA status

Audit log visible per book

Phase 4 â€” Ingestion/storage + delivery (3â€“7 days)

Staging bucket + committed bucket

Hashing + dedupe

Download bundles (zip) or per-file downloads

Rename rules applied automatically

Phase 5 â€” Hardening (ongoing, but quick wins first)

Rate limits

Observability (Sentry + structured logs)

Backoff/retry policies

â€œResume pipelineâ€ and â€œRe-run stageâ€ buttons

Safe-guard rails:

never delete user data automatically

idempotent jobs

immutable audit trail

8) Deployment checklist (Vercel)
Vercel

Next.js app

Environment vars:

DATABASE_URL

STORAGE credentials

QUEUE credentials

AUTH keys

Vercel cron (optional):

reconcile stuck jobs, refresh candidate scoring

Worker host

Dockerized worker (recommended)

Access to queue + DB + storage

Autoscaling (basic)

CI/CD

GitHub Actions:

typecheck/lint

unit tests for normalization + scoring

deploy to Vercel on main

deploy worker on main

9) The â€œcoding is last 10%â€ approach (how to actually do that)

Before any implementation, you and your consultant should produce three artifacts:

Pipeline Spec

states, transitions, error handling

idempotency rules

retry policies

Data Contract

exact JSON payloads for each job type

exact DB schema fields

UI Contract

screens + components + what data each consumes

user actions that trigger transitions

Once those are locked, coding becomes mostly:

wiring + wrappers + UI rendering

not rethinking fundamentals

10) Key design decisions you must choose once

To avoid future chaos, pick these now:

Worker runtime: Node vs Python (match your scripts)

Queue: Upstash Redis (simple) vs Cloudflare Queues (clean)

Storage: S3/R2 vs Supabase Storage

Auth: Clerk vs Supabase Auth

Preview strategy: HEAD requests + partial fetch vs full fetch

If you want the simplest path that matches your â€œlightweight Wikipediaâ€ vibe:

Vercel + Supabase (DB/Auth/Storage) + Upstash Redis queue + Worker on Render/Fly

Thatâ€™s a very common, fast-to-ship, scalable combo.

---

_**Agent (model composer-1, mode Agent)**_



---



---

